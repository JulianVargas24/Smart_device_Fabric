# Smart Device Analytics â€“ Microsoft Fabric (Lakehouse + Warehouse + PySpark)
> Proyecto de ingenierÃ­a de datos con ingesta incremental y full load en Lakehouse, transformaciÃ³n con PySpark + Dataflows Gen2, y anÃ¡lisis en SQL Warehouse con procedimientos almacenados, todo orquestado con pipelines Fabric.

[ğŸ¥ Demo: https://youtu.be/TU-DEMO] (reemplaza con tu enlace real)

---

## 1) Elevator pitch
Este proyecto implementa un flujo de datos robusto y automatizado en Microsoft Fabric:
- Ingesta de archivos CSV desde Azure Data Lake Storage (shortcuts).
- TransformaciÃ³n en capas Bronze â†’ Silver â†’ Gold con PySpark y Dataflows Gen2.
- FunciÃ³n merge_delta_lake para cargas incrementales eficientes.
- Procedimientos almacenados en SQL Warehouse para cargas completas e incrementales.
- Pipelines Fabric con control de errores y ejecuciÃ³n secuencial.

## 2) Arquitectura
Azure Data Lake Storage â”€â”€â–º Lakehouse (Bronze, Silver, Gold) â”€â”€â–º SQL Warehouse â”€â”€â–º Pipelines Fabric â–² â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ingesta, transformaciÃ³n, cargas full/incrementales, control de errores â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- **Fuente**: Archivos CSV en Azure Data Lake Storage.

- **Ingesta**: Notebooks PySpark con esquema explÃ­cito y validaciones.

- **TransformaciÃ³n**:

Bronze â†’ Silver: limpieza y normalizaciÃ³n en formato Delta.

Silver â†’ Gold: cargas incrementales con merge_delta_lake y cargas completas con Dataflows Gen2.

Warehouse: Procedimientos almacenados (sp_full_load, sp_incremental_load) para manejar cargas segÃºn tipo.

OrquestaciÃ³n: Pipelines Fabric que ejecutan ingestiÃ³n, transformaciÃ³n, anÃ¡lisis y refresco, con lÃ³gica de control (If Folder Exists, email error + fail).

## 3) Procesos de IngenierÃ­a de Datos
3.1 Ingesta:
Lectura de CSV desde Bronze con PySpark.

DefiniciÃ³n manual de esquemas para optimizar rendimiento.

ValidaciÃ³n de existencia de carpeta antes de ingesta.

Pipeline con condiciÃ³n: si no existe carpeta â†’ email error + fail.

3.2 TransformaciÃ³n
ConversiÃ³n a Delta Lake en Silver.

Limpieza de columnas, renombrado y normalizaciÃ³n.

FunciÃ³n merge_delta_lake para cargas incrementales: inserta/actualiza registros si la tabla existe, crea tabla si no.

Dataflows Gen2 para cargas completas (dimensiones estÃ¡ticas).

3.3 AnÃ¡lisis en Warehouse
Tablas Gold cargadas al SQL Warehouse.

Procedimientos almacenados:

sp_full_load: recrea tabla completa desde Gold.

sp_incremental_load: inserta/actualiza registros nuevos.

InvocaciÃ³n de procedimientos vÃ­a pipelines con parÃ¡metros dinÃ¡micos.

3.4 OrquestaciÃ³n
Pipelines Fabric:

Ingesta: Bronze â†’ Silver.

TransformaciÃ³n: Silver â†’ Gold.

AnÃ¡lisis: Gold â†’ Warehouse con stored procedures.

Principal: ejecuta todos en secuencia, con control de errores.

4) KPIs de IngenierÃ­a de Datos
% de cargas incrementales exitosas.

Tiempo promedio de ingesta por lote.

Registros insertados vs actualizados en cada merge.

Diferencia entre cargas full vs incrementales.

NÃºmero de procedimientos almacenados ejecutados por ciclo.

5) Stack usado en el proyecto
Microsoft Fabric: Lakehouse, Warehouse, Pipelines, Dataflows Gen2.

PySpark: notebooks para ingesta y transformaciÃ³n, funciÃ³n merge_delta_lake.

SQL Warehouse: procedimientos almacenados para cargas completas e incrementales.

Azure Data Lake Storage: fuente de datos crudos con shortcuts.

GitHub: cÃ³digo, documentaciÃ³n, versionado.
